# Methodology

---

## 1. Problem Setting and Objectives

We evaluate Physics-Informed Neural Networks (PINNs) for learning chaotic dynamics in forced–damped nonlinear systems from sparse, noisy, and partially observed measurements. The forced–damped Duffing oscillator serves as a canonical benchmark due to its sensitive dependence on initial conditions and strange-attractor geometry. The learning task is defined as nonlinear in-domain reconstruction (imputation) over a fixed horizon $t \in [0, T_{\text{end}}]$. Given noisy displacement observations with substantial temporal dropouts, the objective is to recover a continuous latent trajectory within the unobserved gaps by exploiting physics constraints.

### Reconstruction Regimes Relative to the Lyapunov Time

Because chaotic systems diverge exponentially, the notion of correct gap recovery depends on the gap duration relative to the Lyapunov time $\tau_{\lambda} \approx 1/\lambda_{\max}$, where $\lambda_{\max}$ is the largest Lyapunov exponent of the Duffing dynamics under the chosen parameterization. We consider reconstruction gaps of duration $q \in \\{1, 2, 4\\}T$, where $T = 2\pi/\omega$ is the forcing period, under two regimes:

- **Interpolation regime** ($q \lesssim \tau_{\lambda}$). The boundary-conditioned reconstruction problem is well-posed under this regime; success is defined by pointwise accuracy, quantified by RMSE computed strictly on timestamps inside reconstruction gaps.

- **Shadowing regime** ($q \gg \tau_{\lambda}$). Exponential divergence makes unique pointwise recovery ill-posed. In this regime, the objective transitions to shadowing: identifying a physically admissible trajectory that connects the boundary constraints and remains consistent with the attractor. Evaluation therefore emphasizes distributional agreement and attractor consistency over phase-aligned pointwise error.

---

## 2. Governing Dynamics

The forced–damped Duffing oscillator is governed by

$$\ddot{x}(t) + \delta \dot{x}(t) + \alpha x(t) + \beta x(t)^3 = \gamma \cos(\omega t)$$

For learning and constraint enforcement, we employ the first-order formulation with $v(t) = \dot{x}(t)$:

$$\dot{x}(t) = v(t)$$

$$\dot{v}(t) = -\delta v(t) - \alpha x(t) - \beta x(t)^3 + \gamma \cos(\omega t)$$

Parameters $(\alpha, \beta, \delta, \gamma, \omega)$ are fixed to a canonical chaotic regime (reported in full for reproducibility).

---

## 3. Energy Function and Optimization Conditioning

Define the mechanical energy

$$H(x, v) = \frac{1}{2}v^2 + \frac{1}{2}\alpha x^2 + \frac{1}{4}\beta x^4$$

Along true trajectories, the system satisfies the power balance

$$\frac{dH}{dt} = \gamma v \cos(\omega t) - \delta v^2$$

We enforce this balance law in the proposed physics-consistent variant (M2). Although algebraically implied by the governing ODE, explicitly constraining the power flux serves as an optimization-conditioning mechanism: it re-weights gradient information toward high-velocity transients, discouraging solutions that achieve small momentum residuals in a time-averaged sense while exhibiting energetically inconsistent transients.

---

## 4. Data Generation and Masking Protocol

### 4.1 Reference Trajectory and Observations

A reference trajectory is generated by numerical integration of the Duffing system using a high-accuracy adaptive Runge–Kutta solver (absolute and relative tolerances $10^{-9}$). An initial transient interval is discarded to ensure the retained segment lies on the attractor. Displacement is observed at timestamps

$$\mathcal{T}_{\text{all}} = \\{t_j\\}_{j=1}^{N} \subseteq [0, T_{\text{end}}]$$

with additive Gaussian noise

$$x_{\text{obs}}(t_j) = x_{\text{true}}(t_j) + \epsilon_j, \quad \epsilon_j \sim \mathcal{N}(0, \sigma_x^2)$$

Sensor dropout is emulated via a binary mask $m_j \in \\{0, 1\\}$, producing contiguous reconstruction gaps (intervals with $m_j = 0$). The data misfit term is applied only at observed timestamps ($m_j = 1$), whereas physics constraints are enforced over the full horizon using collocation points drawn uniformly from $[0, T_{\text{end}}]$.

### 4.2 Fixed Validation Mask

To mitigate selection bias and ensure reproducibility, we employ a fixed validation mask. Prior to training, 10% of the available observations (timestamps with $m_j = 1$) are randomly held out. This hold-out mask is generated once and applied identically across all model variants and random seeds. Early stopping and hyperparameter selection are performed solely using RMSE on the held-out observed points; reconstruction gaps and physics residuals are excluded from model selection.

---

## 5. Locally Periodic Gaussian Process Regression

To isolate the contribution of learned nonlinear dynamics from spectral interpolation, we compare against Gaussian process regression (GPR) equipped with a locally periodic kernel,

$$k(t, t') = \sigma_f^2 \exp\left(-\frac{2\sin^2(\pi|t - t'|/T)}{\ell_p^2}\right) \exp\left(-\frac{(t - t')^2}{2\ell_g^2}\right) + \sigma_n^2 \delta_{t,t'}$$

The periodicity hyperparameter $T$ is fixed to the known forcing period $2\pi/\omega$. This choice grants the baseline direct access to the dominant drive frequency; consequently, any observed performance gap achieved by the PINN reflects recovery of attractor-consistent nonlinear dynamics rather than simple periodic priors.

---

## 6. PINN Model and Controlled Variants

The PINN parameterizes the state trajectory as $(x\_{\theta}(t), v\_{\theta}(t)) = \text{NN}\_{\theta}(t)$ using a fully-connected MLP with smooth activations, enabling stable automatic differentiation. The initial displacement is anchored to the first noisy observation $x\_{\text{obs}}(0)$. The initial velocity $v\_{\text{init}}$ is treated as a learnable scalar parameter optimized jointly with $\theta$ (and is not taken from ground truth).

Let the data loss (observed timestamps only) be

$$\mathcal{L}_{\text{data}} = \frac{1}{\sum_j m_j} \sum_{j=1}^{N} m_j \left(x_{\theta}(t_j) - x_{\text{obs}}(t_j)\right)^2$$

and the physics residuals be

$$r_1(t) = \dot{x}_{\theta}(t) - v_{\theta}(t)$$

$$r_2(t) = \dot{v}_{\theta}(t) + \delta v_{\theta}(t) + \alpha x_{\theta}(t) + \beta x_{\theta}(t)^3 - \gamma \cos(\omega t)$$

with collocation-based physics loss

$$\mathcal{L}_{\text{phys}} = \frac{1}{|\mathcal{T}_{\text{col}}|} \sum_{t_i \in \mathcal{T}_{\text{col}}} \left(r_1(t_i)^2 + r_2(t_i)^2\right), \quad \mathcal{T}_{\text{col}} \sim \mathcal{U}[0, T_{\text{end}}]$$

We compare three variants under identical architectures, training schedules, and (where applicable) identical random seeds:

**M0 (standard PINN):** Minimizes $\mathcal{L}\_{\text{data}} + \mathcal{L}\_{\text{phys}}$.

**M1 (negative control, physically inconsistent):** Minimizes $\mathcal{L}\_{\text{data}} + \mathcal{L}\_{\text{phys}} + \mathcal{L}\_{\text{Econs}}$, where

$$\mathcal{L}_{\text{Econs}} = \frac{1}{|\mathcal{T}_{\text{col}}|} \sum_{t_i \in \mathcal{T}_{\text{col}}} \left(H_{\theta}(t_i) - H_{\theta}(0)\right)^2$$

enforcing constant energy $H_{\theta}(t) \equiv H_{\theta}(0)$, which is physically inconsistent for a forced–damped system. This control assesses whether observed improvements arise from physically consistent constraints rather than generic regularization.

**M2 (physics-consistent):** Minimizes $\mathcal{L}\_{\text{data}} + \mathcal{L}\_{\text{phys}} + \mathcal{L}\_{\text{Power}}$, where the power-balance residual is

$$r_E(t) = \dot{H}_{\theta}(t) - \left(\gamma v_{\theta}(t)\cos(\omega t) - \delta v_{\theta}(t)^2\right)$$

and

$$\mathcal{L}_{\text{Power}} = \frac{1}{|\mathcal{T}_{\text{col}}|} \sum_{t_i \in \mathcal{T}_{\text{col}}} \left(\frac{r_E(t_i)}{s_{dH}}\right)^2$$

The scale $s_{dH}$ is an RMS normalization computed once from the training data using a fixed velocity proxy (to stabilize weighting near turning points) and treated as constant during optimization.

---

## 7. Evaluation Protocol

### 7.1 Lyapunov Exponent Estimation from the Reconstructed Dynamics

To quantify the stability of the learned dynamics, we estimate the largest Lyapunov exponent $\lambda_{\max}$ via nearest-neighbor divergence computed directly in reconstructed phase space $\mathbf{y}(t) = [x(t), v(t)]^\top$, avoiding delay-embedding hyperparameters. We compute $\lambda_{\max}$ on trajectories sampled on an identical uniform temporal grid over $[0, T_{\text{end}}]$, with no post-hoc smoothing. Divergence is computed in standardized coordinates

$$\tilde{x}(t) = \frac{x(t) - \mu_x}{\sigma_x}, \quad \tilde{v}(t) = \frac{v(t) - \mu_v}{\sigma_v}$$

where $(\mu_x, \mu_v, \sigma_x, \sigma_v)$ are computed once from a long post-transient reference segment and held fixed across all models and seeds. We use a Rosenstein-style nearest-neighbor estimator with a fixed temporal exclusion window (Theiler window) to avoid temporally adjacent neighbors; the divergence rate is obtained by linear regression over a pre-specified fit interval of the log-divergence curve, applied identically across experiments.

### 7.2 Attractor Consistency via Poincaré-Section MMD

Attractor consistency is quantified via Maximum Mean Discrepancy (MMD) computed between predicted and reference stroboscopic Poincaré sections. Stroboscopic samples are collected at forcing-period intervals and restricted to timestamps falling inside reconstruction gaps. To avoid obscuring seed-specific failure modes, Poincaré samples are pooled only within each seed across all gaps in that run to form empirical distributions; MMD is computed independently per seed, and results are reported as mean ± standard deviation over $N = 10$ seeds.

---

## 8. Experimental Design and Evaluation Criteria

All results are averaged over 10 independent random seeds. The methodology is deemed successful if the physics-consistent model (M2) achieves lower Poincaré-section MMD (within gaps) and lower LLE error than both the standard PINN (M0) and the locally periodic GP baseline, while the negative control (M1) fails to improve performance, thereby attributing observed gains specifically to the correctness of the enforced physical constraint.
